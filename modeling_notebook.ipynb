{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author: Ogo Ndugba**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Cancer is a disease that happens when cells grow and multiply uncontrollably. There are more than 100 different types of cancer. Breast cancer happens when cells in a person's breast tissue start growing out of control. Cancer can be very deadly - some cancers have a 5 year survival rate of less than 10%, while others have 5 year survival rate of over 90%. Breast Cancer in particular has a 5 year survival rate of over 90% when it is diagnosed very early - in stage 0 or stage 1. This survival rate falls to 22% if is diagnosed late - when the cancer has spread to other organs stage 4.\n",
    "\n",
    "What's interesting is the fact that cancer is more prevalent in developed countries.\n",
    "\n",
    "![](Images/share-of-population-with-cancer.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "Cancer is very prevalent in the US - we have the highest incidence rating in the developed world. Cancer is the second leading cause of death in the United States. It is responsible for more than 1 in 4 deaths. More than 1.6 million Americans have been diagnosed with cancer each year since 2016. As of 2019, there were more than 16,000,000 Americans living with some form of cancer.\n",
    "\n",
    "Breast Cancer is the most prevalent cancer in the world. There are some 19 million people living with breast cancer. And looking at research - we know that early diagnosis and treatment lead to better survival odds. Out of the more than 100 cancers - we typically only screen for 4 - 6 cancers - depending on what country you live in. These cancers are: breast, prostate, cervical, lung, colorectal, and skin cancer. \n",
    "\n",
    "The tool that is the current gold standard for breast cancer screening is a mammogram.\n",
    "\n",
    "Mammograms are recommended every year or two based a person's risk factors.\n",
    "\n",
    "However mammograms arent perfect. They have a false positive rate of anywhere from 10-20% - according to several studies. They also have a false negative rate of about 15%. \n",
    "\n",
    "These error rates are increased for women who have dense breast tissue, are younger, and are women of color. \n",
    "\n",
    "The goal of this project is to develop a machine learning classification algorithmn for the National Institues of health that is more reliable at finding instances of breast cancer and also mimimzing the false negative and false positive rates.\n",
    "\n",
    "![](Images/number-of-people-with-cancer-by-type.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "\n",
    "The data for this project comes from the BreakHis dataset on Kaggle. It contains 7,909 images - of which 2480 are benign (no cancer) and 5429 are malignant (cancer). [\"Kaggle\"](https://www.kaggle.com/datasets/ambarish/breakhis). This images were collected from \"82 patients using different magnifying factors (40X, 100X, 200X, and 400X)\". Approximately 70% of the images in our dataset were malignant. \n",
    "\n",
    "\n",
    "![](Images/Distribution-of-Mammogram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing Packages\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import splitfolders\n",
    "import itertools\n",
    "from matplotlib.image import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.metrics import recall_score, ConfusionMatrixDisplay, plot_roc_curve\n",
    "from sklearn.metrics import precision_score, classification_report \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models, layers, optimizers, metrics, regularizers, losses\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers import scikit_learn\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(2004)\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing split folders package\n",
    "#pip install split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the splitfolders package to split the images into train, validation, and test sets.\n",
    "# this is now commented out so that a new folder isnt created each time notebook is run\n",
    "\n",
    "\n",
    "# splitfolders.ratio(\"CancerData\", output=\"Data\",\n",
    "# seed=42, ratio=(.64, .16, .2), group_prefix=None, move=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using ImageDataGenerator to rescale all images \n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        'Data/train',\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(150, 150),\n",
    "        batch_size=5061,\n",
    "        color_mode='grayscale',\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = val_datagen.flow_from_directory('Data/val',\n",
    "                                                        target_size=(150, 150),\n",
    "                                                        batch_size=1264,\n",
    "                                                        color_mode='grayscale',\n",
    "                                                        class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory('Data/test',\n",
    "                                                  target_size=(150, 150),\n",
    "                                                  batch_size=1584,\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the augumented data\n",
    "aug_train_images = ImageDataGenerator(rotation_range=30, \n",
    "                                   width_shift_range=0.25, \n",
    "                                   height_shift_range=0.25, \n",
    "                                   shear_range=0.25, \n",
    "                                   zoom_range=0.25, \n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "\n",
    "train_aug = aug_train_images.flow_from_directory('Data/train',\n",
    "                                                  target_size=(150, 150),\n",
    "                                                  batch_size=3747,\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting images and labels for models\n",
    "train_data, train_labels = next (train_generator)\n",
    "test_data, test_labels = next (test_generator)\n",
    "val_data, val_labels = next (validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshaping for our Simple Model - dimension needs to be 2D \n",
    "train_data = train_data.reshape(train_data.shape[0], -1)\n",
    "test_data = test_data.reshape(test_data.shape[0], -1)\n",
    "val_data = val_data.reshape(val_data.shape[0], -1)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show confusion matrix \n",
    "##from sklearn\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy Model\n",
    "I will use a dummy model classifier as the baseline model. This model will predict the majority class. Since the majority class in our data is malignant, this model will predict all images are malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate our DummyModel and fit to train dataset\n",
    "dummy_model =  DummyClassifier(strategy='most_frequent')\n",
    "dummy_model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating predictions to evalaute model \n",
    "y_pred = (dummy_model.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting metrics for model\n",
    "dummy_acc = dummy_model.score(test_data, test_labels)\n",
    "dummy_rec = recall_score(test_labels,y_pred)\n",
    "dummy_pre = precision_score(test_labels,y_pred)\n",
    "\n",
    "print(f\"Dummy Model accuracy: {dummy_acc}\")\n",
    "print(f\"Dummy Model recall: {dummy_rec}\")\n",
    "print(f\"Dummy Model precision: {dummy_pre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating confusion matrix\n",
    "cm = confusion_matrix(y_true= test_labels, y_pred=y_pred) \n",
    "cm_labels = ['Benign','Malignant']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_labels, title='Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model 1\n",
    "The first model will be a basic simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating neural network model\n",
    "simple_model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giving input and output layers\n",
    "simple_model.add(layers.Dense(12, activation='relu', input_shape=(22500,)))\n",
    "simple_model.add(layers.Dense(1, activation='sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling model and printing summary\n",
    "simple_model.compile(optimizer='SGD',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training our simple model and validating using out subset of validation data\n",
    "simple_model_history = simple_model.fit(train_data, train_labels, epochs=10, \n",
    "                                    batch_size=32, validation_data= (val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing metrics\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(15,8))\n",
    "\n",
    "loss = simple_model_history.history['loss']\n",
    "accuracy = simple_model_history.history['accuracy']\n",
    "precision = simple_model_history.history['precision']\n",
    "recall = simple_model_history.history['recall']\n",
    "\n",
    "validation_loss = simple_model_history.history['val_loss']\n",
    "validation_accuracy = simple_model_history.history['val_accuracy']\n",
    "validation_precision = simple_model_history.history['val_precision']\n",
    "validation_recall = simple_model_history.history['val_recall']\n",
    "\n",
    "sns.lineplot(simple_model_history.epoch, simple_model_history.history['loss'], y=loss, ax=ax1, label='loss')\n",
    "sns.lineplot(simple_model_history.epoch, simple_model_history.history['val_loss'], y=loss, ax=ax1, label='val_loss')\n",
    "\n",
    "\n",
    "sns.lineplot(simple_model_history.epoch, simple_model_history.history['accuracy'], y=accuracy, ax=ax2, label='accuracy')\n",
    "sns.lineplot(simple_model_history.epoch, simple_model_history.history['val_accuracy'], y=accuracy, ax=ax2, label='val_accuracy')\n",
    "\n",
    "\n",
    "sns.lineplot(simple_model_history.epoch, simple_model_history.history['precision'], y=precision, ax=ax3, label='precision')\n",
    "sns.lineplot(simple_model_history.epoch, simple_model_history.history['val_precision'], y=precision, ax=ax3, label='val_precision')\n",
    "\n",
    "\n",
    "sns.lineplot(simple_model_history.epoch, simple_model_history.history['recall'], y=recall, ax=ax4, label='recall')\n",
    "sns.lineplot(simple_model_history.epoch, simple_model_history.history['val_recall'], y=recall, ax=ax4, label='val_recall');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating predictions to test model metrics against validation data\n",
    "y_pred = (simple_model.predict(val_data) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(y_true= val_labels, y_pred=y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing confusion matrix\n",
    "cm_labels = ['Benign','Malignant']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_labels, title='Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model\n",
    "results = simple_model.evaluate(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# getting model metrics\n",
    "print(f\"Model loss:  {results[0]}\")\n",
    "print(f\"Model accuracy: {results[1]}\")\n",
    "print(f\"Model precision: {results[2]}\")\n",
    "print(f\"Model recall: {results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model 2\n",
    "Added another layer to the basic simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model2 = models.Sequential([\n",
    "    layers.Flatten(input_shape=(22500,1)),\n",
    "    layers.Dense(32, activation='relu', input_shape=(22500,)),\n",
    "    layers.Dense(1, activation='sigmoid')]\n",
    "# compiling model and printing summary\n",
    "simple_model2.compile(optimizer='SGD',\n",
    "                       loss='binary_crossentropy',\n",
    "                       metrics=['accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])\n",
    "simple_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training our simple model and validating using out subset of validation data\n",
    "simple_model2_history = simple_model2.fit(train_data, train_labels, epochs=20, \n",
    "                                    batch_size=None, validation_data= (val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing metrics\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(15,8))\n",
    "\n",
    "loss = simple_model2_history.history['loss']\n",
    "accuracy = simple_model2_history.history['accuracy']\n",
    "precision = simple_model2_history.history['precision']\n",
    "recall = simple_model2_history.history['recall']\n",
    "\n",
    "validation_loss = simple_model2_history.history['val_loss']\n",
    "validation_accuracy = simple_model2_history.history['val_accuracy']\n",
    "validation_precision = simple_model2_history.history['val_precision']\n",
    "validation_recall = simple_model2_history.history['val_recall']\n",
    "\n",
    "sns.lineplot(simple_model2_history.epoch, simple_model2_history.history['loss'], y=loss, ax=ax1, label='loss')\n",
    "sns.lineplot(simple_model2_history.epoch, simple_model2_history.history['val_loss'], y=loss, ax=ax1, label='val_loss')\n",
    "\n",
    "\n",
    "sns.lineplot(simple_model2_history.epoch, simple_model2_history.history['accuracy'], y=accuracy, ax=ax2, label='accuracy')\n",
    "sns.lineplot(simple_model2_history.epoch, simple_model2_history.history['val_accuracy'], y=accuracy, ax=ax2, label='val_accuracy')\n",
    "\n",
    "\n",
    "sns.lineplot(simple_model2_history.epoch, simple_model2_history.history['precision'], y=precision, ax=ax3, label='precision')\n",
    "sns.lineplot(simple_model2_history.epoch, simple_model2_history.history['val_precision'], y=precision, ax=ax3, label='val_precision')\n",
    "\n",
    "\n",
    "sns.lineplot(simple_model2_history.epoch, simple_model2_history.history['recall'], y=recall, ax=ax4, label='recall')\n",
    "sns.lineplot(simple_model2_history.epoch, simple_model2_history.history['val_recall'], y=recall, ax=ax4, label='val_recall');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating predictions to test model metrics against validation data\n",
    "y_pred = (simple_model2.predict(val_data) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(y_true= val_labels, y_pred=y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing confusion matrix\n",
    "cm_labels = ['Benign','Malignant']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_labels, title='Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating model\n",
    "results = simple_model2.evaluate(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting model metrics\n",
    "print(f\"Model loss:  {results[0]}\")\n",
    "print(f\"Model accuracy: {results[1]}\")\n",
    "print(f\"Model precision: {results[2]}\")\n",
    "print(f\"Model recall: {results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Models \n",
    "Started off with a Convulution Neural Network model and built several iterations with it - from adding different types of layers, to adding a regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#recreating data sets for our CNN models  - dimension needs to be 4D \n",
    "train_data, train_labels = next (train_generator)\n",
    "test_data, test_labels = next (test_generator)\n",
    "val_data, val_labels = next (validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1_model = models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                    input_shape=(150, 150, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(16, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "cnn1_model.compile(optimizer=\"adam\",\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])\n",
    "\n",
    "cnn1_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1_history = cnn1_model.fit(train_data,\n",
    "               train_labels,\n",
    "               batch_size=10,\n",
    "               epochs=20,\n",
    "               validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(15,8))\n",
    "\n",
    "sns.lineplot(cnn1_history.epoch, cnn1_history.history['loss'], y=loss, ax=ax1, label='loss')\n",
    "sns.lineplot(cnn1_history.epoch, cnn1_history.history['val_loss'], y=loss, ax=ax1, label='val_loss')\n",
    "\n",
    "sns.lineplot(cnn1_history.epoch, cnn1_history.history['accuracy'], y=accuracy, ax=ax2, label='accuracy')\n",
    "sns.lineplot(cnn1_history.epoch, cnn1_history.history['val_accuracy'], y=accuracy, ax=ax2, label='val_accuracy')\n",
    "\n",
    "sns.lineplot(cnn1_history.epoch, cnn1_history.history['precision'], y=precision, ax=ax3, label='precision')\n",
    "sns.lineplot(cnn1_history.epoch, cnn1_history.history['val_precision'], y=precision, ax=ax3, label='val_precision')\n",
    "\n",
    "sns.lineplot(cnn1_history.epoch, cnn1_history.history['recall'], y=recall, ax=ax4, label='recall')\n",
    "sns.lineplot(cnn1_history.epoch, cnn1_history.history['val_recall'], y=recall, ax=ax4, label='val_recall');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (cnn1_model.predict(val_data) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(y_true= val_labels, y_pred=y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_labels = ['Benign','Malignant']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_labels, title='Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cnn1_model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Model loss:  {results[0]}\")\n",
    "print(f\"Model accuracy: {results[1]}\")\n",
    "print(f\"Model precision: {results[2]}\")\n",
    "print(f\"Model recall: {results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_model = models.Sequential( [layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                            input_shape=(150,150,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),      \n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(12, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid') ])\n",
    "\n",
    "cnn2_model.compile(optimizer=\"adam\",\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])\n",
    "\n",
    "cnn2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2_history = cnn2_model.fit(train_data,\n",
    "               train_labels,\n",
    "               batch_size=20,\n",
    "               epochs=20,\n",
    "               validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(15,8))\n",
    "\n",
    "sns.lineplot(cnn2_history.epoch, cnn2_history.history['loss'], y=loss, ax=ax1, label='loss')\n",
    "sns.lineplot(cnn2_history.epoch, cnn2_history.history['val_loss'], y=loss, ax=ax1, label='val_loss')\n",
    "\n",
    "sns.lineplot(cnn2_history.epoch, cnn2_history.history['accuracy'], y=accuracy, ax=ax2, label='accuracy')\n",
    "sns.lineplot(cnn2_history.epoch, cnn2_history.history['val_accuracy'], y=accuracy, ax=ax2, label='val_accuracy')\n",
    "\n",
    "sns.lineplot(cnn2_history.epoch, cnn2_history.history['precision'], y=precision, ax=ax3, label='precision')\n",
    "sns.lineplot(cnn2_history.epoch, cnn2_history.history['val_precision'], y=precision, ax=ax3, label='val_precision')\n",
    "\n",
    "sns.lineplot(cnn2_history.epoch, cnn2_history.history['recall'], y=recall, ax=ax4, label='recall')\n",
    "sns.lineplot(cnn2_history.epoch, cnn2_history.history['val_recall'], y=recall, ax=ax4, label='val_recall');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (cnn2_model.predict(val_data) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(y_true= val_labels, y_pred=y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_labels = ['Benign','Malignant']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_labels, title='Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cnn2_model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model loss:  {results[0]}\")\n",
    "print(f\"Model accuracy: {results[1]}\")\n",
    "print(f\"Model precision: {results[2]}\")\n",
    "print(f\"Model recall: {results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3_model = models.Sequential( [layers.Conv2D(64, (4, 4), activation='relu', \n",
    "                            input_shape=(150,150,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (4,4), activation='relu'),      \n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(12, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid') ])\n",
    "\n",
    "cnn2_model.compile(optimizer=\"adam\",\n",
    "                        loss='binary_crossentropy',\n",
    "                        metrics=['accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])\n",
    "\n",
    "cnn2_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3_history = cnn3_model.fit(train_data,\n",
    "               train_labels,\n",
    "               batch_size=20,\n",
    "               epochs=20,\n",
    "               validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(15,8))\n",
    "\n",
    "sns.lineplot(cnn3_history.epoch, cnn3_history.history['loss'], y=loss, ax=ax1, label='loss')\n",
    "sns.lineplot(cnn3_history.epoch, cnn3_history.history['val_loss'], y=loss, ax=ax1, label='val_loss')\n",
    "\n",
    "sns.lineplot(cnn3_history.epoch, cnn3_history.history['accuracy'], y=accuracy, ax=ax2, label='accuracy')\n",
    "sns.lineplot(cnn3_history.epoch, cnn3_history.history['val_accuracy'], y=accuracy, ax=ax2, label='val_accuracy')\n",
    "\n",
    "sns.lineplot(cnn3_history.epoch, cnn3_history.history['precision'], y=precision, ax=ax3, label='precision')\n",
    "sns.lineplot(cnn3_history.epoch, cnn3_history.history['val_precision'], y=precision, ax=ax3, label='val_precision')\n",
    "\n",
    "sns.lineplot(cnn3_history.epoch, cnn3_history.history['recall'], y=recall, ax=ax4, label='recall')\n",
    "sns.lineplot(cnn3_history.epoch, cnn3_history.history['val_recall'], y=recall, ax=ax4, label='val_recall');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (cnn3_model.predict(val_data) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(y_true= val_labels, y_pred=y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_labels = ['Benign','Malignant']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_labels, title='Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cnn3_model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model loss:  {results[0]}\")\n",
    "print(f\"Model accuracy: {results[1]}\")\n",
    "print(f\"Model precision: {results[2]}\")\n",
    "print(f\"Model recall: {results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4_model = models.Sequential()\n",
    "cnn4_model.add(layers.Conv2D(64, (4, 4), activation='relu',\n",
    "                       input_shape=(150, 150, 1), kernel_regularizer=regularizers.l2(l=0.05)))\n",
    "cnn4_model.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn4_model.add(layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                                     kernel_regularizer=regularizers.l2(l=0.05)))\n",
    "cnn4_model.add(layers.MaxPooling2D((2,2)))\n",
    "cnn4_model.add(layers.Flatten())\n",
    "cnn4_model.add(layers.Dense(16, activation='relu'))\n",
    "cnn4_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn4_model.compile(optimizer=\"adam\",\n",
    "                          loss='binary_crossentropy',\n",
    "                          metrics=['accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])\n",
    "cnn4_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn4_history = cnn4_model.fit(train_data,\n",
    "              train_labels,\n",
    "              batch_size=32,\n",
    "              epochs=10,\n",
    "              validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(15,8))\n",
    "\n",
    "sns.lineplot(cnn4_history.epoch, cnn4_history.history['loss'], y=loss, ax=ax1, label='loss')\n",
    "sns.lineplot(cnn4_history.epoch, cnn4_history.history['val_loss'], y=loss, ax=ax1, label='val_loss')\n",
    "\n",
    "sns.lineplot(cnn4_history.epoch, cnn4_history.history['accuracy'], y=accuracy, ax=ax2, label='accuracy')\n",
    "sns.lineplot(cnn4_history.epoch, cnn4_history.history['val_accuracy'], y=accuracy, ax=ax2, label='val_accuracy')\n",
    "\n",
    "sns.lineplot(cnn4_history.epoch, cnn4_history.history['precision'], y=precision, ax=ax3, label='precision')\n",
    "sns.lineplot(cnn4_history.epoch, cnn4_history.history['val_precision'], y=precision, ax=ax3, label='val_precision')\n",
    "\n",
    "sns.lineplot(cnn4_history.epoch, cnn4_history.history['recall'], y=recall, ax=ax4, label='recall')\n",
    "sns.lineplot(cnn4_history.epoch, cnn4_history.history['val_recall'], y=recall, ax=ax4, label='val_recall');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (cnn4_model.predict(val_data) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(y_true= val_labels, y_pred=y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_labels = ['Benign','Malignant']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_labels, title='Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cnn4_model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model loss:  {results[0]}\")\n",
    "print(f\"Model accuracy: {results[1]}\")\n",
    "print(f\"Model precision: {results[2]}\")\n",
    "print(f\"Model recall: {results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn5_model = models.Sequential()\n",
    "cnn5_model.add(layers.Conv2D(64, (4, 4), activation='relu',\n",
    "                       input_shape=(150, 150, 1), kernel_regularizer=regularizers.l2(l=0.05)))\n",
    "cnn5_model.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn5_model.add(layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                                     kernel_regularizer=regularizers.l2(l=0.05)))\n",
    "cnn5_model.add(layers.MaxPooling2D((2,2)))\n",
    "cnn5_model.add(layers.Flatten())\n",
    "cnn5_model.add(layers.Dense(16, activation='relu'))\n",
    "cnn5_model.add(layers.Dropout(0.5))\n",
    "cnn5_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn5_model.compile(optimizer=\"adam\",\n",
    "                          loss='binary_crossentropy',\n",
    "                          metrics=['accuracy', metrics.Precision(name='precision'), metrics.Recall(name='recall')])\n",
    "\n",
    "cnn5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn5_history = cnn5_model.fit(train_data,\n",
    "               train_labels,\n",
    "               batch_size=32,\n",
    "               epochs=10,\n",
    "               validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(15,8))\n",
    "\n",
    "sns.lineplot(cnn5_history.epoch, cnn5_history.history['loss'], y=loss, ax=ax1, label='loss')\n",
    "sns.lineplot(cnn5_history.epoch, cnn5_history.history['val_loss'], y=loss, ax=ax1, label='val_loss')\n",
    "\n",
    "sns.lineplot(cnn5_history.epoch, cnn5_history.history['accuracy'], y=accuracy, ax=ax2, label='accuracy')\n",
    "sns.lineplot(cnn5_history.epoch, cnn5_history.history['val_accuracy'], y=accuracy, ax=ax2, label='val_accuracy')\n",
    "\n",
    "sns.lineplot(cnn5_history.epoch, cnn5_history.history['precision'], y=precision, ax=ax3, label='precision')\n",
    "sns.lineplot(cnn5_history.epoch, cnn5_history.history['val_precision'], y=precision, ax=ax3, label='val_precision')\n",
    "\n",
    "sns.lineplot(cnn5_history.epoch, cnn5_history.history['recall'], y=recall, ax=ax4, label='recall')\n",
    "sns.lineplot(cnn5_history.epoch, cnn5_history.history['val_recall'], y=recall, ax=ax4, label='val_recall');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (cnn5_model.predict(val_data) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(y_true= val_labels, y_pred=y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_labels = ['Benign','Malignant']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_labels, title='Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cnn5_model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model loss:  {results[0]}\")\n",
    "print(f\"Model accuracy: {results[1]}\")\n",
    "print(f\"Model precision: {results[2]}\")\n",
    "print(f\"Model recall: {results[3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall all of the CNN models had similar metrics. I chose Model 3 as the best performing model because it overall it had a higher accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "The final model uses Model 3 to evaluate the test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cnn3_model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model loss:  {results[0]}\")\n",
    "print(f\"Model accuracy: {results[1]}\")\n",
    "print(f\"Model precision: {results[2]}\")\n",
    "print(f\"Model recall: {results[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (cnn3_model.predict(test_data) > 0.5).astype(\"int32\")\n",
    "cm = confusion_matrix(y_true= test_labels, y_pred=y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_labels = ['Benign','Malignant']\n",
    "plot_confusion_matrix(cm=cm, classes=cm_labels, title='Confusion Matrix');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Results\n",
    "In this project, I was trying to build a model that would do better than the current accepted error rates - the False Positive rate of 10-20% and the False Negative rate of 15%. I built several models to make the classification. I trained the models with training data and validated using the validation data. \n",
    "\n",
    "Based on the validation metrics - I chose the model that had the best overall metrics and ran it with the test data. I built 8 models- including the dummy model. Unfortunately - the results I achieved werent great- I wasnt able to hit 85% on any of my metrics - accuracy, precision, or recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion & Next Steps\n",
    "In conclusion, my best model did not do well at classifying images as benign or malignant. \n",
    "\n",
    "As for potential next steps, these images were taken from a pretty small sample of people - 82 patients. There was no accompanying clinical information - did the patient have dense breast tissue, and if they had cancer - what stage was the image from, what specific type of breast cancer. There was also no demographic information provided.\n",
    "\n",
    "Increasing the sample size to a number that is significant and providing some demographic and clinical information could lead to better results.\n",
    "\n",
    "Also there is some research to suggest that there are other ways that would be more accurate at diagnosing breast cancer - using MRIS, cell free DNA and cell tumor DNA seem to hold some promise as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
